#!/usr/bin/env python3
"""
ğŸ¦– AI Provider Fallback Hierarchy Display
Show the complete fallback chain for Restaceratops AI system
"""

import asyncio
from dotenv import load_dotenv
from agent.openrouter_ai_system import get_openrouter_ai_system
from agent.enhanced_ai_system import get_enhanced_ai_system

# Load environment variables
load_dotenv()

def show_fallback_hierarchy():
    """Display the complete AI provider fallback hierarchy."""
    print("ğŸ¦– Restaceratops AI Provider Fallback Hierarchy")
    print("=" * 60)
    
    # Get OpenRouter system
    openrouter_ai = get_openrouter_ai_system()
    openrouter_stats = openrouter_ai.get_system_stats()
    
    # Get Enhanced AI system
    enhanced_ai = get_enhanced_ai_system()
    enhanced_stats = enhanced_ai.get_system_stats()
    
    print("1ï¸âƒ£ PRIMARY: OpenRouter AI System")
    print("   â””â”€â”€ 10 Free Models (Automatic Rotation)")
    print("       â”œâ”€â”€ openai/gpt-3.5-turbo")
    print("       â”œâ”€â”€ anthropic/claude-3-haiku")
    print("       â”œâ”€â”€ google/gemini-2.5-flash-lite")
    print("       â”œâ”€â”€ qwen/qwen3-235b-a22b-2507:free")
    print("       â”œâ”€â”€ z-ai/glm-4.5-air")
    print("       â”œâ”€â”€ meta-llama/llama-3.1-8b-instruct")
    print("       â”œâ”€â”€ microsoft/phi-3.5-mini-128k")
    print("       â”œâ”€â”€ deepseek-ai/deepseek-coder-6.7b-instruct")
    print("       â”œâ”€â”€ mistralai/mistral-7b-instruct")
    print("       â””â”€â”€ nousresearch/nous-hermes-2-mixtral-8x7b-dpo")
    print()
    
    print("2ï¸âƒ£ FALLBACK: Enhanced AI System")
    print("   â””â”€â”€ Multiple Provider Support")
    
    # Show enhanced AI providers from the multi-provider component
    if hasattr(enhanced_ai, 'multi_provider_ai'):
        for i, provider in enumerate(enhanced_ai.multi_provider_ai.providers, 1):
            status = "âœ…" if provider["name"] not in enhanced_ai.multi_provider_ai.failed_providers else "âŒ"
            print(f"       {i}. {status} {provider['name']} ({provider['type']})")
    else:
        print("       â€¢ DeepSeek API Keys (5 accounts)")
        print("       â€¢ Hugging Face API Tokens (5 accounts)")
        print("       â€¢ Ollama Local Model")
        print("       â€¢ OpenAI API (if configured)")
    
    print()
    print("ğŸ”„ FALLBACK LOGIC:")
    print("   â€¢ OpenRouter tries each model in sequence")
    print("   â€¢ If a model fails (rate limit, error), moves to next")
    print("   â€¢ If all OpenRouter models fail, switches to Enhanced AI")
    print("   â€¢ Enhanced AI tries DeepSeek â†’ HuggingFace â†’ Ollama")
    print("   â€¢ If all fail, uses built-in fallback responses")
    print()
    
    print("ğŸ“Š CURRENT STATUS:")
    print(f"   â€¢ OpenRouter: {openrouter_stats['working_models']}/{openrouter_stats['total_models']} models ready")
    print(f"   â€¢ Enhanced AI: {enhanced_stats['working_providers']}/{enhanced_stats['total_providers']} providers ready")
    print(f"   â€¢ Current OpenRouter Model: {openrouter_stats['current_model']}")
    print(f"   â€¢ Current Enhanced AI Provider: {enhanced_stats['current_provider']}")
    print()
    
    print("âœ… Your system is configured for maximum reliability!")
    print("   With 319+ free models available through OpenRouter + fallback providers")

if __name__ == "__main__":
    show_fallback_hierarchy() 